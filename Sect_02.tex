%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{OpenCL and Device Fission}

OpenCL consists of an API for coordinating \textit{parallel computation across heterogeneous processors} (CPU, GPU and other processors) and it is supported by a wide range of systems and platforms, making it the perfect choice for parallel computation not only on traditional desktop CPU-GPU configuration, but also on embedded systems.


%-----------------------------------------------------------------------------
\subsection{OpenCL Architecture}

%OpenCL is a framework which is composed of 4 main components:
%
%\begin{enumerate}
%	\item a \textbf{language} [APPROFONDIRE]
%	\item an \textbf{API} [APPROF]
%	\item a series of \textbf{libraries} [APPROF]
%	\item a \textbf{runtime system} [APPROF]
%\end{enumerate}
%
%To better describe the architecture of OpenCL, we can divide it into four models:
%
%\subsubsection{The Platform Model}
We can define the structure of an OpenCL application by defining its components. Some of these components are purely abstract and refer to the "`software"' part of the application (the host), devices mixes both software and hardware abstraction, while Compute Units and Processing Elements are direct references to the graphic hardware.

\begin{itemize}
	\item the \textbf{Host} can be viewed as the "`outer control logic"' of the application. It is usually executed on the CPU and its function is to configure the application accordingly to the architecture of the hosting machine, and to submit commands to the computing units.
	\item one or more \textbf{OpenCL Devices} connected to the host. These devices can be physical (e.g. the graphic adapter installed on the system) or virtual (e.g. remote GPUs in a cluster configuration - for more info about OpenCL clustering refer to the VCL project, http://wwww.mosix.org)
	\item various \textbf{Compute Units} (CU) that are the equivalent of CUDA's Stream Multiprocessors introduced in \textbf{Figure} \ref{fig:scalability}. A Compute Unit can be viewed as a thread that is executing on a single core of a multicore CPU, or a thread executing on one of the Stream Processors of the GPU.
	\item each Compute Unit is divided into several \textbf{Processing Elements} (PE). Each PE can work both in \textbf{SIMD} mode (Single Instruction Multiple Data), therefore exploiting \textit{data level parallelism} and \textbf{SPMD} mode (Single Program Multiple Data): the program is divided into independent task that are executed simultaneously.
	Each PE has it own program counter.
\end{itemize}

The architecture of an OpenCL application is summarized in \textbf{Figure} \ref{fig:OpenCLArch}:

\begin{figurehere}
 \centering
 \includegraphics[width=8cm, height=4cm]{./eps/OpenCLArch.eps}
 \caption{OpenCL Architecture}
 \label{fig:OpenCLArch}
\end{figurehere}

\begin{CLCode}
A List containing all the available devices on a system can be obtained calling the \textbf{clGetDeviceIDs()} function. 
\end{CLCode}


\subsubsection{Execution and Index Space}

From a very coarse point of view, we can describe the execution of an OpenCL application as a two-step process:

\begin{enumerate}
	\item the \textbf{host} define the context for \textbf{kernels} and submit them for execution.
	\item the \textbf{kernel} executes on one or more OpenCL device and compute over a stream of data.
\end{enumerate}

In OpenCL, an instance of a kernel is called \textbf{work-item} and it executes over an \textbf{index-space} that is defined every time a new kernel is submitted. We can see the index space as the data domain over which the multiple instances of a kernel may work, and it is also called \textbf{NDRange} (N-dimensional index space, where N is one, two or three). From the graphical point of view of the GPU computation, the index range is no more than the texture on which apply the shader (in fact GPUs normally support 1,2 or 3-dimensional textures).\\

\begin{figurehere}
 \centering
 \includegraphics[width=8cm, height=4cm]{./eps/index-space.eps}
 \caption{Work-items mapped over a 2-D NDRange. As you can see, work-items can be organized in Work-Groups. Every work-item has both global and local IDs inside its work-group.}
 \label{fig:indexSpace}
\end{figurehere}

\subsubsection{Program Context and Command-Queue} \label{sect:context}

When the host defines the \textbf{context} for the application, it basically define four things:

\begin{enumerate}
	\item the collection of OpenCL devices to be used
	\item the collection of functions that will be executed on the devices (that is, the kernels)
	\item \textbf{program objects}, that are simply the source files and executables that implements the kernels
	\item \textbf{memory objects}: the data to be computed
\end{enumerate}

After the context has been created, the host initialize a structure called \textbf{command queue} that is used to schedule commands onto the devices within the context. The command structure is very simple and the main commands issued by the host are only three:

\begin{enumerate}
	\item \textbf{Kernel execution commands}: Execute a kernel on the PEs (Processing Elements) of a device
	\item \textbf{Memory commands}: Transfer data to, from, or between memory objects, or map and unmap
memory objects from the host address space.
	\item	\textbf{Synchronization commands}: Used to specify the order of execution of commands.
\end{enumerate}

\subsubsection{Memory}

There are four types of memory regions in OpenCL: \textbf{Global}, \textbf{Constant}, \textbf{Local} and \textbf{Private}.

\begin{itemize}
	\item Global memory grants read/write access to \textbf{all} the work-items in every work-group.
	\item Constant memory is only used to store constants. Only the host has write privileges over it, while kernels can only read from it.
	\item Local memory is shared among all the work-items that form a group. The host has no access to this memory.
	\item Private memory is allocated directly by the work-item and can be used only by itself. The host has no access to this part of memory.
\end{itemize}

Since computation is carried on parallely, one of the major issues about memory is \textbf{consistency}. OpenCL uses a relaxed consistency memory model: the state of memory visible to a work-item is not guaranteed to be consistent across the collection of work-items at all times. \textbf{Table} \ref{tab:memconsistency} summarizes memory consistency for the various regions of memory available.\\

\begin{tablehere}
{\footnotesize
\begin{tabular}{|p{2cm}|p{5,5cm}|} \hline
\textbf{Memory} & \textbf{Consistency}\\ \hline
Private & memory is not shared, read/write consistency is always guaranteed\\ \hline
Local & consistency is guaranteed between work-items of the same work-group\\ \hline
Global & consistency is guaranteed between work-items of the same work-group, but not between multiple work-groups in the case they are assigned to execute the same kernel\\ \hline
\end{tabular}}
\caption{Memory consistency}
\label{tab:memconsistency}
\end{tablehere}


In OpenCL computation is performed over \textbf{memory objects}. There are two distinct memory objects: \textbf{buffers} and \textbf{images}.

\begin{itemize}
	\item Buffers are used to store a one-dimensional collection of elements (like an array), and those elements can be scalar values (int, float, etc.), vectors or user defined structures.
	Buffers are stored sequentially and \emph{can be accessed using pointers}; elements of a buffer are stored in memory in the \emph{same format} as they are used by kernels (i.e. if the kernel works on single integers, these elements are stored in memory as integers, this is not true for image objects)
	\item Images are used to store bi- or three-dimensional structures and their elements cannot be only selected by a list of predefined image formats (i.e. you cannot simply declare int or floats in an image object). Differently from buffers, elements of images \emph{cannot be accessed directly with a pointer} and they are \emph{always stored in memory as 4-dimensinal vectors} (since graphic shaders work on RGB and Alpha components of the pixels of an image)
\end{itemize}

\begin{CLCode}
In OpenCL memory objects are stored into \textbf{cl\_mem} structs, that can be easily initializated with the \textbf{clCreateBuffer()} and \textbf{clCreateImage()} functions.\\
Image format availables may vary from one graphic adapter to another, a list of supported image formats can be obtained using the \textbf{clGetSupportedImageFormats()} query.
\end{CLCode}





%-----------------------------------------------------------------------------
\subsection{Device Fission}

Device Fission is an extension of the OpenCL specification (fully defined in the OpenCL 1.2 specification, although is available as an extension of OpenCL 1.1 as well) that allow more control over parallel application.\\
As the term 'fission' implies (the action of dividing or splitting something into two or more parts), device fission allows the sub-dividing of a device into one or more sub-devices. This can be used to control manually which CU (Compute Unit) executes specific openCL commands. This practice, when used carefully, can provide a performance advantage, especially when executing the code on the CPU instead of the GPU.\cite{intel:12:DeviceFission}\\
Using device fission does require some knowledge of the underlying target hardware. Device fission should be used carefully and may impact code portability and performance if not used properly.

\subsubsection{Device Fission for Embedded Systems}
Device fissioning can be very useful in an embedded environment (or any other environment where resources are limited) for several reasons:

\begin{itemize}
	\item Device fission allows to use only a \emph{portion} of a device, this means that the OpenCL runtime will not take the entire device for itself and other non-OpenCL application can work on it at the same time.
	\item Devife fission can allow specialized memory sharing models (For example see the partitioning by affinity domain described in \textbf{Section} \ref{DF-subdevices})
\end{itemize}

\subsubsection{Sub Devices} \label{sect:DF-subdevices}
Each subdevice can have its own \textbf{context} and \textbf{command-queue} (See \textbf{Section} \ref{sect:context})

\begin{CLCode}
In OpenCL you can create new sub-devices using the \textbf{clCreateSubDevices()} function. The first parameter to pass is of type \textbf{cl\_device\_id} and it is the ID of the device that has to be partitioned. You can query for a list of available devices on the system by using the \textbf{clGetDeviceIDs()} function. Each sub-device can have a maximum number of compute units specified by the \textbf{CL\_DEVICE\_PARTITION\_MAX\_COMPUTE\_UNITS} property.
\end{CLCode}

There are three main way to partition a device: \textbf{equally}, \textbf{by counts} and \textbf{by affinity domain}.

\begin{itemize}
	\item partitioning a device \textbf{equally} means that the application will try to split the device into as many sub-devices as possible, each containting a number of CUs specified by the programmer. If that number does not divide evenly into the maximum available compute units, the remaining are not used.
	\item \textbf{by counts} means that the device is not divided automatically (and equally), but accordinlgy to a list provided by the programmer (e.g. given the list (4,8,16) the device will be divided into three sub-devices containing respectively 4,8 and 16 CUs)
	\item partitioning by \textbf{affinity domain} is an automatic process that will create sub-devices composed of CUs that share similar levels of cache-hierarchy (specified by the programmer, e.g. L1,L2,L3 caches or NUMA nodes). This can be very useful when micro-management of memory is useful or for system where memory is a critical factor (for example in  embedded systems)
\end{itemize}





