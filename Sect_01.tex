%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{GPGPU Introduction}

GPGPU (\textit{General Purpose computation on Graphics Processor Unit}), also known as \textit{GPU Computing}, is the utilization of the graphic adapter of a personal computer to perform generic and non-graphic related computation usually handled by the CPU.\\
Once designed and optimized specifically to perform only graphic calculations, modern GPUs are evolving into \emph{high-performances many-core} processors that can be virtually used to perform any task, and developers who port their applications to GPUs are able to achieve speedups of orders of magnitude vs. optimized CPU implementations.\cite{GPGPUORG:About}\\
The reason why GPUs are so fast has to be searched in the nature of what graphic rendering is about: a compute-intensive parallel computetion. For this reason, GPUs are engineered to work on data processing, rather than data caching and flow control like the CPUs are.

\begin{figurehere}
 \centering
 \includegraphics[width=8cm, height=4cm]{./eps/GPU_CPU_struct.eps}
 \caption{GPU is less about cache and more about computation}
 \label{fig:cpuvsgpu_scheme}
\end{figurehere}

Ottimizzate per fare poche e semplici operazioni su vertici e matrici, ma in PARALLELO -> parallelismo intriseco.
GPUs have been built to exploit application parallelism, and a single graphic adapter can host hundreds, if not thousands, of cores; this translates in TeraFlops of operations per second vs. the few GigaFlops a CPU can handle alone.//
 (incremento più alto di legge di moore?)

\begin{figurehere}
 \centering
 \includegraphics[width=8cm, height=4cm]{./eps/GPU_CPU_chart.eps}
 \caption{CPU vs GPU growth rate.}
 \label{fig:cpuvsgpu}
\end{figurehere}


-esempi applicativi
Due to its parallel nature, GPU computing can be very effective for applications involving huge amount of data, especially if the data can be structured in structures like vectors and arrays.
Parallel GPU computation can be applied in various applications and research-field, from computer vision, to mathematical simulations, to bio-informatics, often allowing to achieve in few months results that would have required years with a standard CPU-only approach (with speedups of even 250x,350x).

METTERE GRAFICO DEL PAPER??

As seen in TAB, GPU can offload the CPU from most of its work, but this doesn't mean that CPU performance is no longer critical. Many applications don't (and can't) map all their code to the GPU, and in certain cases the CPU can run some part of the code more effectively than the GPU.
Furthermore, not all the code can be mapped easily and clearly on the GPU, as programming in this say can be way more difficult than programming in a standard way, it is not possible to simply "`port"' the code from the CPU to the GPU.
-problemi: difficoltà

%-----------------------------------------------------------------------------
\subsection{Basic Principles} \label{sect:principles}
% Please avoid separations in titles
% and separate text manually

In this section we'll analyze some of the basic principles behind GPGPU programming. Some of these concepts are directly related to and help to understand why GPU computing is so fast, for instance, GPUs can handle bidimensional matrices natively, while CPUs are limited to single dimension array.
A GPU is basically a \textit{stream processor}: a \textbf{kernel} is executed over a stream of data in a monolitic fashion.
Thanks to the GPU architecture, the data can be elaborated in parallel, and more than one kernel can be running at the same time. (VERIFICARE?)

\subsubsection{Textures = Arrays}
Due to the linear structure of memory, traditional CPUs cannot \emph{physically} create multi-dimensional array, and accessing rows and columns of a simple matrix is obtained by offsetting coordinates in a large one-dimensional array, each "`jump"' in memory translates in performance loss.
GPUs are architectured to work natively with textures, that can be seen as two-dimensional array. One drawback is that the amount of memory on graphics adapters is limited, compared to the system RAM available to the CPU, and for this reason most of the GPUs can work only with textures of a limited size. The usual maximum size of a texture is usually 2048*2048, or 4096*4096, but modern can reach sizes of 8192*8192.
The maximum texture size available for a certain graphic adapter can usually be retrieved by simple queries made available by the API you are using.

\begin{CLCode}
In OpenCL, you can obtain the maximum supported texture size with the \textsl{clGetDeviceInfo()} function, passing the
\textsl{CL\_DEVICE\_IMAGE2D\_MAX\_WIDTH} and \textsl{CL\_DEVICE\_IMAGE2D\_MAX\_HEIGHT} parameters.
\end{CLCode}

We will discuss how textures are created and accessed more in deep in Section \ref{}, when we will introduce the OpenCL API.

\subsubsection{Kernels}
If you are familiar with graphic programming, kernels are the GPGPU equivalent for \textbf{shaders}.
Kernel programming is the core concept of the GPU computation and forces the developer to think [..] in a different way, as kernels are oriented toward \emph{data-parallelism} implementation, while standard CPU programming is oriented toward a \emph{loop-iteration} implementation, in fact, we can think of kernels as bodies of a loop cycle.
Since our data is stored into multi-dimensional \textbf{textures}, this texture will be fed to the kernel, that will execute its code over each [..] in parallel, the result of each computation will be found at the same texture coordinate in the output structure. We must keep in mind that GPUs were born to elaborate graphics data, so basically a shader works by applying the same operation over each pixel of an image to obtain a different result.
Here's an example of a simple shader written in HLSL language, it basically scan the entire texture for completely black pixels and turn them to white:

{\footnotesize\begin{verbatim}
float4 BlackToWhite(PixelShaderInput input)
{
  if(input.Color.r == 0 &&
	   input.Color.g == 0 && 
     input.Color.b == 0)
     return float4(1,1,1,1);
  else
     return input.Color;
}
\end{verbatim}}

The same code in a traditional loop-oriented approach will be something like:

{\footnotesize\begin{verbatim}
void BlackToWhite(float input[4096][4096][4],
                  float output* [4096][4096][4])
{
  for	(int y=0,y<4096,y++)
    for(int x=0;x<4096;x++)
    {
      if(input[x][y][0] == 0 &&
         input[x][y][1] == 0 &&
         input[x][y][2] == 0)
      {
         *output[x][y][0] = 1;
         *output[x][y][1] = 1;
         *output[x][y][2] = 1;
         *output[x][y][3] = 1;
      }
      else
      {
         *output[x][y][0] = input[x][y][0];
         *output[x][y][1] = input[x][y][1];
         *output[x][y][2] = input[x][y][2];
         *output[x][y][3] = input[x][y][3];
      }
    }
}
\end{verbatim}}


By comparing the two examples, we can note two things:

\begin{enumerate}
	\item In the shader we do not implement any cycle, the code is iterated \emph{automatically} on every element of the input structure. Also there is no mapping between the input and the output, but only a single \textbf{return}. This because the output is automatically assigned to the same texture coordinate of the input.
	\item Since GPU are meant to work with colors, shaders can natively work on 4 different channels at a time (RGBA), making GPU computation even more versatile and powerful.
\end{enumerate}

Since shaders are written to work with graphics ... GPU computation ... APIs that allow to work easily on data without having to write shaders directly. We will introduce some of these APIs in Section \ref{}

\subsubsection{Computation and feedback}
Keeping in mind that GPU's purpose is to draw something on screen, we cannot simply "`run"' our kernels, but we have to make the graphics adapter think that it is actually drawing something, that is, in GPU computing, "`to execute"' translates in "`\textit{to draw}"'.
The basic operations for a simple render are:\\


\begin{table*}[t]
{\footnotesize
    \begin{tabular}{|p{0,5cm}|p{8cm}|p{8cm}|}\hline
        ~  & \textbf{Drawing perspective} & \textbf{Computation perspective} \\ \hline
        1) & Assign the input texture to a texture channel of the graphic adapter & Define the input data and passing it 	to the kernel          \\ \hline
        2) & Setting the drawing surface & Define where the output data will be stored                 \\ \hline
        3) & Define the quad to be drawn. The quad must fit the entire viewport and the texture must be mapped to it. & Initializing the indices and setting the bounds of the loop \\ \hline
        4)  & Load the shader &   ~                                                          \\ \hline
        5) & Render the quad & Iterate through data and execute the kernel. \\ \hline
        
    \end{tabular}}
	\label{tab:computeVsDraw}
\end{table*}

After the drawing (the computation) has been performed, the result is stored in the target surface.

%This is a citation \cite{Norman09Learn} and here is another citation
%\cite{Peyton93Howto}.  Lorem ipsum dolor sit amet, consectetur adipiscing elit.


%And this is the reference to a single column figure (see {\bf Figure
%\ref{fig:myfigure1}}).  Lorem ipsum dolor sit amet, consectetur adipiscing elit.

\begin{figurehere}
 \centering
 \includegraphics[width=8cm, height=4cm]{./eps/placeholder.eps}
 \caption{Some single-column figure caption.}
 \label{fig:myfigure1}
\end{figurehere}


%-----------------------------------------------------------------------------
\subsection{GPGPU Programming Languages}

In this section we will briefly introduce the most common languages and APIs to develop GPGPU applications.

\subsubsection{CUDA (www.nvidia.com)} \label{sect:CUDA}
CUDA is the parallel programming platform introduced by Nvidia in 2006 and it has currently reached version 5.
The main focus of CUDA is on \textbf{automatic scalability}: the program model forces the programmer to partition the main problem into coarse sub-problems that can be solved independently in parallel, and these threads are automatically scaled in runtime over the many cores different GPUs may have (\textbf{Figure \ref{fig:scalability}}).

\begin{figurehere}
 \centering
 \includegraphics[width=8cm, height=4cm]{./eps/scalability.eps}
 \caption{CUDA executables are automatically scaled over the various SMs (Stream Multiprocessors) a GPU may have : a GPU with more multiprocessors will automatically execute the program in less time than a GPU with fewer multiprocessors.}
 \label{fig:scalability}
\end{figurehere}

CUDA is mainly based on C-language and follow the programming model introduced in Section \ref{sect:principles}, with \textit{Kernels} and introduces new concepts like \textbf{thread hiearchy} (allowing to create \textit{multi-dimensional thread blocks} that can be executed in parallel) and \textbf{memory hierarchy} (for example each thread has its own local memory and can share memory with thread in their own block).\\
On the downside, since it is a proprietary framework, CUDA executables will only run on Nvidia graphic cards, and the code cannot fall back on the CPU in the case a CUDA accelerated hardware is not available on the system.\cite{siroro:GPUComparison}

\subsubsection{OpenCL (www.khronos.org/opencl/)}
OpenCL (Open Computing Language) is the parallel programming model developed by the Khronos group that focuses on cross-platforming: differently from CUDA, OpenCL is supported on a wide range of devices and can also be used on some embedded or mobile devices like Android phones and iPhones.\\
The current version of OpenCL is 1.2 and it was released in 2011.
We will discuss OpenCL more in deep in Section \ref{}.

\subsubsection{DirectCompute}
Also known as Computer Shader (for more info refer to the msdn library: http://msdn.microsoft.com/) is the GPU computing API developed by Microsoft which is part of the DirectX APIs collection starting from version 11.
Since it is part of the DirectX package, DirectCompute uses HLSL shading language and integrates well with applications already written with the DirectX API, however, its compatibility is limited to desktop graphic adapters that supports DX10 or 11 and only for Windows (Vista or later) operating systems.

\begin{figure*}[t]
  \centering
 \includegraphics[width=16cm, height=4cm]{./eps/placeholder.eps}
 \caption{Some wide-figure caption.}
 \label{fig:myfigure2}
\end{figure*}

And this is the reference to a single column figure (see {\bf Figure
\ref{fig:myfigure2}}). Lorem ipsum dolor sit amet, consectetur adipiscing elit.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%